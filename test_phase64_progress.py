#!/usr/bin/env python3
"""
Test Phase 6.4 Progress Tracking & Analytics
Test trá»±c tiáº¿p vá»›i backend vÃ  database
"""
import asyncio
import sys
import os
sys.path.append('.')

import json
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient
from app.services.study_session_service import study_session_service
from app.services.progress_analytics_service import progress_tracker, historical_analytics, achievement_system
from app.models.study import StudySessionStartRequest, FlashcardAnswerRequest, StudyMode

async def test_phase64_progress_tracking():
    """Test complete Phase 6.4 progress tracking features"""
    
    print("=== PHASE 6.4 PROGRESS TRACKING & ANALYTICS TEST ===")
    print(f"ğŸ• Started at: {datetime.now()}")
    print("-" * 60)
    
    # 1. Initialize services
    print("1. ğŸš€ Service Initialization")
    try:
        await study_session_service.initialize()
        await historical_analytics.initialize()
        await achievement_system.initialize()
        
        print("   âœ… All services initialized")
        
        # Test data
        user_id = "6899b990a2518f8e4a47e0ab"
        deck_id = "6894f7d942907590250f3fb9"
        
    except Exception as e:
        print(f"   âŒ Service initialization failed: {e}")
        return False
    
    # 2. Create test session for progress tracking
    print("2. ğŸ“Š Session Progress Tracking Test")
    try:
        session_request = StudySessionStartRequest(
            deck_id=deck_id,
            study_mode=StudyMode.PRACTICE,
            target_cards=5,
            target_time=30,
            break_reminders_enabled=True,
            break_interval=15
        )
        
        session_response = await study_session_service.start_session(
            user_id=user_id,
            session_request=session_request
        )
        
        session_id = session_response.id
        print(f"   âœ… Test session created: {session_id}")
        
        # Submit some answers to generate progress data
        current_card = session_response.current_card
        
        # Answer 1: Correct
        answer_1 = FlashcardAnswerRequest(
            flashcard_id=current_card.id,
            quality=4,
            response_time=8.5,
            was_correct=True,
            answer_text="Good answer"
        )
        
        answer_response_1 = await study_session_service.submit_answer(
            session_id=session_id,
            user_id=user_id,
            answer_request=answer_1
        )
        
        print(f"   ğŸ“ˆ First answer processed: Progress {answer_response_1.completion_percentage:.1f}%")
        
        # Answer 2: Incorrect
        if answer_response_1.next_card:
            answer_2 = FlashcardAnswerRequest(
                flashcard_id=answer_response_1.next_card.id,
                quality=2,
                response_time=15.0,
                was_correct=False,
                answer_text="Wrong answer"
            )
            
            answer_response_2 = await study_session_service.submit_answer(
                session_id=session_id,
                user_id=user_id,
                answer_request=answer_2
            )
            
            print(f"   ğŸ“ˆ Second answer processed: Progress {answer_response_2.completion_percentage:.1f}%")
        
        # Test real-time progress calculation
        session_data = await study_session_service.db.study_sessions.find_one({"_id": session_id})
        if session_data:
            # Fix ObjectId issue
            session_data["_id"] = str(session_data["_id"])
            
            progress_metrics = progress_tracker.calculate_session_progress(session_data)
            
            print(f"   ğŸ“Š Real-time Progress Metrics:")
            print(f"     â±ï¸ Time elapsed: {progress_metrics['time_elapsed_minutes']} minutes")
            print(f"     ğŸ“‡ Cards completed: {progress_metrics['cards_completed']}/{progress_metrics['total_cards']}")
            print(f"     ğŸ¯ Accuracy: {progress_metrics['accuracy_percentage']:.1f}%")
            print(f"     ğŸ”¥ Current streak: {progress_metrics['current_streak']}")
            print(f"     âš¡ Avg response time: {progress_metrics['average_response_time']:.2f}s")
            print(f"     ğŸ“ˆ Learning velocity: {progress_metrics['learning_velocity']:.2f} cards/min")
            print(f"     ğŸ¯ Completion: {progress_metrics['completion_percentage']:.1f}%")
        
    except Exception as e:
        print(f"   âŒ Progress tracking test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 3. Historical Analytics Test
    print("3. ğŸ“ˆ Historical Analytics Test")
    try:
        # Get session history
        session_history = await historical_analytics.get_session_history(
            user_id=user_id,
            limit=5,
            days_back=30
        )
        
        print(f"   ğŸ“Š Session History (last 30 days): {len(session_history)} sessions")
        for i, session in enumerate(session_history[:3], 1):
            print(f"   ğŸ“‹ Session {i}: {session['study_mode']} - {session['accuracy']:.1f}% accuracy")
            print(f"       ğŸ“… {session['started_at']} - {session['cards_studied']} cards")
        
        # Get user statistics
        user_stats = await historical_analytics.get_user_statistics(
            user_id=user_id,
            days_back=30
        )
        
        print(f"   ğŸ“Š User Statistics (30 days):")
        print(f"     ğŸ“š Total sessions: {user_stats['total_sessions']}")
        print(f"     âœ… Completed: {user_stats['completed_sessions']}")
        print(f"     ğŸš« Abandoned: {user_stats['abandoned_sessions']}")
        print(f"     ğŸ“ˆ Completion rate: {user_stats['completion_rate']:.1f}%")
        print(f"     â±ï¸ Total study time: {user_stats['total_study_time_minutes']:.1f} minutes")
        print(f"     ğŸ“‡ Total cards studied: {user_stats['total_cards_studied']}")
        print(f"     ğŸ¯ Overall accuracy: {user_stats['overall_accuracy']:.1f}%")
        print(f"     ğŸ”¥ Daily streak: {user_stats['daily_study_streak']} days")
        print(f"     ğŸ¯ Preferred mode: {user_stats['preferred_study_mode']}")
        
    except Exception as e:
        print(f"   âŒ Historical analytics test failed: {e}")
        import traceback
        traceback.print_exc()
    
    # 4. Progress Dashboard Test
    print("4. ğŸ“Š Progress Dashboard Test")
    try:
        dashboard = await historical_analytics.get_progress_dashboard(user_id=user_id)
        
        print(f"   ğŸ“Š Dashboard Generated at: {dashboard['dashboard_generated_at']}")
        
        # Weekly stats
        weekly = dashboard['weekly_stats']
        print(f"   ğŸ“ˆ Weekly Stats:")
        print(f"     ğŸ“š Sessions: {weekly['total_sessions']}")
        print(f"     ğŸ¯ Accuracy: {weekly['overall_accuracy']:.1f}%")
        print(f"     â±ï¸ Study time: {weekly['total_study_time_minutes']:.1f} minutes")
        
        # Monthly stats
        monthly = dashboard['monthly_stats']
        print(f"   ğŸ“Š Monthly Stats:")
        print(f"     ğŸ“š Sessions: {monthly['total_sessions']}")
        print(f"     ğŸ¯ Accuracy: {monthly['overall_accuracy']:.1f}%")
        print(f"     â±ï¸ Study time: {monthly['total_study_time_minutes']:.1f} minutes")
        
        # Deck mastery
        deck_mastery = dashboard['deck_mastery']
        print(f"   ğŸ“š Deck Mastery Progress: {len(deck_mastery)} decks")
        for deck in deck_mastery[:2]:
            print(f"     ğŸ“– {deck['deck_title']}: {deck['mastery_percentage']:.1f}% mastered")
            print(f"       ğŸ“Š {deck['studied_cards']}/{deck['total_cards']} cards studied")
        
        # SRS overview
        srs = dashboard['srs_overview']
        print(f"   ğŸ§  SRS Overview:")
        print(f"     ğŸ“‡ Total cards in SRS: {srs['total_cards_in_srs']}")
        print(f"     â° Due today: {srs['due_today']}")
        print(f"     ğŸ“… Due tomorrow: {srs['due_tomorrow']}")
        print(f"     âš ï¸ Overdue: {srs['overdue_cards']}")
        print(f"     ğŸ“‹ Review load: {srs['review_load']}")
        
        # Study patterns
        patterns = dashboard['study_patterns']
        print(f"   ğŸ“Š Study Patterns:")
        print(f"     â° Peak hour: {patterns['peak_study_hour']}:00")
        print(f"     ğŸ“… Peak day: {patterns['peak_study_day']}")
        print(f"     ğŸ“Š Sessions analyzed: {patterns['total_sessions_analyzed']}")
        
        # Achievements
        achievements = dashboard['achievements']
        print(f"   ğŸ† Recent Achievements: {len(achievements)}")
        for achievement in achievements:
            print(f"     {achievement['icon']} {achievement['title']}: {achievement['description']}")
        
    except Exception as e:
        print(f"   âŒ Dashboard test failed: {e}")
        import traceback
        traceback.print_exc()
    
    # 5. Achievement System Test
    print("5. ğŸ† Achievement System Test")
    try:
        # Complete the test session to trigger achievements
        completion_response = await study_session_service.complete_session(
            session_id=session_id,
            user_id=user_id,
            completion_type="manual"
        )
        
        print(f"   âœ… Session completed for achievement testing")
        print(f"   ğŸ“Š Final accuracy: {completion_response.accuracy_rate:.1f}%")
        print(f"   ğŸ”¥ Best streak: {completion_response.best_streak}")
        
        # Check for new achievements
        session_data = await study_session_service.db.study_sessions.find_one({"_id": session_id})
        if session_data:
            session_data["_id"] = str(session_data["_id"])
            new_achievements = await achievement_system.check_achievements(user_id, session_data)
            
            print(f"   ğŸ† New achievements earned: {len(new_achievements)}")
            for achievement in new_achievements:
                print(f"     {achievement['icon']} {achievement['title']}: {achievement['description']}")
                if 'points' in achievement:
                    print(f"       ğŸ’ Points: {achievement['points']}")
        
        # Get all user achievements
        all_achievements = await achievement_system.db.user_achievements.find({
            "user_id": user_id
        }).sort("achieved_at", -1).limit(5).to_list(length=5)
        
        print(f"   ğŸ† Total achievements in database: {len(all_achievements)}")
        for ach in all_achievements:
            print(f"     {ach['icon']} {ach['title']} - {ach['achieved_at']}")
        
    except Exception as e:
        print(f"   âŒ Achievement system test failed: {e}")
        import traceback
        traceback.print_exc()
    
    # 6. Database Analytics Verification
    print("6. ğŸ—„ï¸ Database Analytics Verification")
    try:
        db = study_session_service.db
        
        # Count analytics data
        total_sessions = await db.study_sessions.count_documents({})
        total_progress = await db.user_flashcard_progress.count_documents({})
        total_achievements = await db.user_achievements.count_documents({})
        
        # User-specific counts
        user_sessions = await db.study_sessions.count_documents({"user_id": user_id})
        user_progress = await db.user_flashcard_progress.count_documents({"user_id": user_id})
        user_achievements = await db.user_achievements.count_documents({"user_id": user_id})
        
        print(f"   ğŸ“Š Database Analytics Summary:")
        print(f"     ğŸ“š Total sessions: {total_sessions}")
        print(f"     ğŸ“ˆ Total progress records: {total_progress}")
        print(f"     ğŸ† Total achievements: {total_achievements}")
        print(f"     ğŸ‘¤ User sessions: {user_sessions}")
        print(f"     ğŸ‘¤ User progress: {user_progress}")
        print(f"     ğŸ‘¤ User achievements: {user_achievements}")
        
        # Check session status distribution
        status_counts = await db.study_sessions.aggregate([
            {"$group": {"_id": "$status", "count": {"$sum": 1}}}
        ]).to_list(length=None)
        
        print(f"   ğŸ“Š Session Status Distribution:")
        for status in status_counts:
            print(f"     {status['_id']}: {status['count']} sessions")
        
        # Check study mode preferences
        mode_counts = await db.study_sessions.aggregate([
            {"$group": {"_id": "$study_mode", "count": {"$sum": 1}}}
        ]).to_list(length=None)
        
        print(f"   ğŸ“Š Study Mode Preferences:")
        for mode in mode_counts:
            print(f"     {mode['_id']}: {mode['count']} sessions")
        
    except Exception as e:
        print(f"   âŒ Database verification failed: {e}")
    
    print("-" * 60)
    print("ğŸ‰ PHASE 6.4 PROGRESS TRACKING TEST FINISHED!")
    print(f"ğŸ• Finished at: {datetime.now()}")
    
    return True

async def main():
    """Main test function"""
    try:
        success = await test_phase64_progress_tracking()
        if success:
            print("\nâœ… Phase 6.4 Progress Tracking & Analytics: WORKING PERFECTLY!")
            print("ğŸ“Š Real-time progress tracking functional!")
            print("ğŸ“ˆ Historical analytics comprehensive!")
            print("ğŸ† Achievement system operational!")
            print("ğŸ“Š Dashboard generation successful!")
            print("ğŸš€ Ready for Phase 6.5 or production!")
        else:
            print("\nâŒ Some features need fixing")
    except Exception as e:
        print(f"\nğŸ’¥ Critical error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
